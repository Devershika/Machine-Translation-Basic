# Machine-Translation-Basic
Machine Translation (MT) refers to the use of computational models and algorithms to automatically translate text or speech from one language to another. It is a core task in Natural Language Processing (NLP) and has evolved from rule-based systems to statistical approaches and now to neural machine translation (NMT) powered by deep learning.

## Types of Machine Translation Approaches
### 1. Rule-Based Machine Translation (RBMT)

* Relies on linguistic rules (syntax, morphology, grammar).
* Uses bilingual dictionaries and hand-crafted rules.
* Example: Early MT systems like SYSTRAN.
* Advantage: Transparent and explainable translations.
* Limitation: Requires extensive linguistic resources; lacks scalability.

### 2. Statistical Machine Translation (SMT)

Based on probabilistic models derived from large bilingual corpora.
Translations are generated by maximizing the probability of the target sentence given the source sentence.
Key models:
  Word-based models
  Phrase-based SMT (PB-SMT)
  Hierarchical and syntax-based SMT
  Example: Moses Toolkit.
Advantage: Data-driven, more scalable.
Limitation: Struggles with long-distance dependencies, word reordering.

### 3. Neural Machine Translation (NMT)

Uses deep learning models (RNNs, LSTMs, GRUs, Transformers).
Treats translation as a sequence-to-sequence (seq2seq) problem.
Attention mechanisms (Bahdanau, Luong) and Transformers (Vaswani et al., 2017) revolutionized MT.
Examples: Google Translate (modern version), OpenNMT, MarianNMT, HuggingFace Transformers.
Advantage: Produces fluent, context-aware translations.
Limitation: Requires large datasets and high computational power.
